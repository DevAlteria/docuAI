services:
  ollama:
    volumes:
      - ollama-data-vol:/root/.ollama
    container_name: ollama
    restart: unless-stopped
    image: docker.io/ollama/ollama:0.6.1
    ports:
      - 7869:11434
    environment: #https://github.com/ollama/ollama/issues/2941
      - OLLAMA_HOST=${OLLAMA_HOST:-http://0.0.0.0:11434}
      # - OLLAMA_ORIGINS=${OLLAMA_ORIGINS:-[localhost, 127.0.0.1, 0.0.0.0, iaDoc.alteria.vpn.alonsom.com, gpus.alteria.vpn.alonsom.com]}
      - OLLAMA_MODELS=${OLLAMA_MODELS:-/root/.ollama/models}
      - OLLAMA_KEEP_ALIVE=${OLLAMA_KEEP_ALIVE:-5m}
      - OLLAMA_DEBUG=${OLLAMA_DEBUG:-false}
      - OLLAMA_FLASH_ATTENTION=${OLLAMA_FLASH_ATTENTION:-false}
      - OLLAMA_NOHISTORY=${OLLAMA_NOHISTORY:-false}
      - OLLAMA_NOPRUNE=${OLLAMA_NOPRUNE:-false}
      - OLLAMA_SCHED_SPREAD=${OLLAMA_SCHED_SPREAD:-false}
      - OLLAMA_INTEL_GPU=${OLLAMA_INTEL_GPU:-false}
      # TODO complete
      # - OLLAMA_LLM_LIBRARY=${OLLAMA_LLM_LIBRARY:-""}
      # - OLLAMA_TMPDIR=${OLLAMA_TMPDIR:-/tmp}
      # - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-}
      # - HIP_VISIBLE_DEVICES=${HIP_VISIBLE_DEVICES:-}
      # - OLLAMA_RUNNERS_DIR=${OLLAMA_RUNNERS_DIR:-}
      - OLLAMA_NUM_PARALLEL=${OLLAMA_NUM_PARALLEL:-0}
      - OLLAMA_MAX_LOADED_MODELS=${OLLAMA_MAX_LOADED_MODELS:-0}
      - OLLAMA_MAX_QUEUE=${OLLAMA_MAX_QUEUE:-512}
      - OLLAMA_MAX_VRAM=${OLLAMA_MAX_VRAM:-0}
    networks:
      - ollama-docker
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all 
              capabilities: [gpu]

  ollama-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: ollama-webui
    volumes:
      - webui-data-vol:/app/backend/data
    depends_on:
      - ollama
    ports:
      - 8080:8080
    environment: # https://docs.openwebui.com/getting-started/env-configuration#default_models
      - WEBUI_URL=${WEBUI_URL:-http://localhost:8080}
      - ENABLE_SIGNUP=${ENABLE_SIGNUP:-true}
      - ENABLE_LOGIN_FORM=${ENABLE_LOGIN_FORM:-true}
      - DEFAULT_LOCALE=${DEFAULT_LOCALE:-en}
      - DEFAULT_MODELS=${DEFAULT_MODELS:-}
      - DEFAULT_USER_ROLE=${DEFAULT_USER_ROLE:-admin}
      - PENDING_USER_OVERLAY_TITLE=${PENDING_USER_OVERLAY_TITLE:-""}
      - ENV=dev
      - ENABLE_PERSISTENT_CONFIG=true
      - WEBUI_NAME=iaDoc
      - PORT=8080
      - WEBUI_AUTH=False
      - WEBUI_SECRET_KEY=t0p-s3cr3t
      # OLLAMA
      - ENABLE_OLLAMA_API=true
      - OLLAMA_BASE_URLS=http://ollama:7869 #comma separated ollama hosts
      - USE_OLLAMA_DOCKER=false #always false we have another container for this
      - K8S_FLAG=false #for helm deployment
    restart: unless-stopped
    networks:
      - ollama-docker
  n8n:
    restart: unless-stopped
    build:
      context: ../../src/n8n/
      dockerfile: Dockerfile
    image: n8n:1.0.0
    container_name: n8n
    volumes:
      - n8n-data-vol:/home/node/.n8n
      - ../../src/n8n/scripts/:/home/node/scripts
      - ../../src/n8n/config/config.json:/n8n-config.json
      - ../../src/n8n/credentials/:/credentials/
      - ../../src/n8n/workflows/:/workflows/
    networks:
      - ollama-docker
    ports:
      - 5678:5678
    environment:
      - N8N_PATH=/n8n/
      - N8N_HOST=iadoc.alteria.vpn.alonsom.com
      - N8N_LISTEN_ADDRESS=0.0.0.0
      - N8N_PROTOCOL=http 
      - N8N_SECURE_COOKIE=false
  nginx:
    image: nginx:alpine-1.0.0
    build:
      context: ../../src/nginx/
      dockerfile: Dockerfile
    container_name: nginx
    restart: unless-stopped
    ports:
      - "80:80"
      # - "443:443"
    volumes:
      - ../../src/nginx/conf/http.d:/etc/nginx/http.d:ro
      - ../../src/nginx/conf/nginx.conf:/etc/nginx/nginx.conf:ro
      - ../../src/nginx/public/:/var/www/html/iaDoc/:ro
    networks:
      - ollama-docker

networks:
  ollama-docker:
    driver: bridge
    name: ollama-docker
    external: false

volumes:
  webui-data-vol:
    driver: local
    name: webui-data-vol
    driver_opts:
      type: none
      o: bind
      device: ${PWD}/envs/dev/data/webui-data-vol
  ollama-data-vol:
    driver: local
    name: ollama-data-vol
    driver_opts:
      type: none
      o: bind
      device: ${PWD}/envs/dev/data/ollama-data-vol
  n8n-data-vol:
    driver: local
    name: n8n-data-vol
    driver_opts:
      type: none
      o: bind
      device: ${PWD}/envs/dev/data/n8n-data-vol

